{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset,DataLoader\nimport torchvision\nfrom torchvision import transforms,models\nimport torch.optim as optim\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom PIL import Image\nfrom PIL import ImageFile\nimport albumentations","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ClassificationDataset(Dataset):\n    def __init__(self ,image_paths, targets, resize=None, augmentations=None):\n        self.image_paths = image_paths\n        self.targets = targets\n        self.resize = resize\n        self.augmentations = augmentations\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, item):\n        image = Image.open(self.image_paths[item])\n        image = image.convert(\"RGB\")\n        targets = self.targets[item]\n\n        if self.resize is not None:\n            image = image.resize((self.resize[1], self.resize[0]),\n                                 resample=Image.BILINEAR)\n\n        image = np.array(image)\n\n        if self.augmentations is not None:\n            augmented = self.augmentations(image=image)\n            image = augmented['image']\n\n        # torch expects CxHxW instead of HxWxC\n        image = np.transpose(image, (2,0,1)).astype(np.float32)\n\n        image = torch.tensor(image, dtype=torch.float)\n        targets = torch.tensor(targets, dtype=torch.long)\n\n        return (image, targets)\n","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"root_dir = \"../input/jpeg-melanoma-256x256/\"\ntrain_csv = pd.read_csv(root_dir + 'train.csv')\n\ndef get_train_val_split(df):\n    #Removing Duplicates\n    df = df[df.tfrecord != -1].reset_index(drop=True)\n    train_tf_records = list(range(len(df.tfrecord.unique())))[:12]\n    split_cond = df.tfrecord.apply(lambda x: x in train_tf_records)\n    train_df = df[split_cond].reset_index()\n    valid_df = df[~split_cond].reset_index()\n    return train_df,valid_df\n\ntrain_files, test_files = get_train_val_split(train_csv)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_image_ids = train_files.image_name.values.tolist()\ntrain_images = [os.path.join(root_dir + 'train/' ,i +'.jpg') for i in train_image_ids]\ntrain_targets = train_files.target.values\n\ntest_image_ids = test_files.image_name.values.tolist()\ntest_images = [os.path.join(root_dir + 'train/' ,i +'.jpg') for i in test_image_ids]\ntest_targets = test_files.target.values","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_files.head()","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"   index    image_name  patient_id   sex  age_approx  \\\n0      6  ISIC_0074542  IP_4698288  male        25.0   \n1     10  ISIC_0076545  IP_9802602  male        55.0   \n2     17  ISIC_0079038  IP_5295861  male        70.0   \n3     18  ISIC_0080512  IP_1870306  male        75.0   \n4     24  ISIC_0082934  IP_6572129  male        65.0   \n\n  anatom_site_general_challenge diagnosis benign_malignant  target  tfrecord  \\\n0               lower extremity   unknown           benign       0        14   \n1               upper extremity   unknown           benign       0        14   \n2                         torso   unknown           benign       0        13   \n3                         torso   unknown           benign       0        12   \n4                         torso   unknown           benign       0        12   \n\n   width  height  \n0   5184    3456  \n1   4288    2848  \n2   6000    4000  \n3   6000    4000  \n4   6000    4000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>image_name</th>\n      <th>patient_id</th>\n      <th>sex</th>\n      <th>age_approx</th>\n      <th>anatom_site_general_challenge</th>\n      <th>diagnosis</th>\n      <th>benign_malignant</th>\n      <th>target</th>\n      <th>tfrecord</th>\n      <th>width</th>\n      <th>height</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>ISIC_0074542</td>\n      <td>IP_4698288</td>\n      <td>male</td>\n      <td>25.0</td>\n      <td>lower extremity</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n      <td>14</td>\n      <td>5184</td>\n      <td>3456</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10</td>\n      <td>ISIC_0076545</td>\n      <td>IP_9802602</td>\n      <td>male</td>\n      <td>55.0</td>\n      <td>upper extremity</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n      <td>14</td>\n      <td>4288</td>\n      <td>2848</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>17</td>\n      <td>ISIC_0079038</td>\n      <td>IP_5295861</td>\n      <td>male</td>\n      <td>70.0</td>\n      <td>torso</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n      <td>13</td>\n      <td>6000</td>\n      <td>4000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>18</td>\n      <td>ISIC_0080512</td>\n      <td>IP_1870306</td>\n      <td>male</td>\n      <td>75.0</td>\n      <td>torso</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n      <td>12</td>\n      <td>6000</td>\n      <td>4000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>24</td>\n      <td>ISIC_0082934</td>\n      <td>IP_6572129</td>\n      <td>male</td>\n      <td>65.0</td>\n      <td>torso</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n      <td>12</td>\n      <td>6000</td>\n      <td>4000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_files.head()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"   index    image_name  patient_id     sex  age_approx  \\\n0      0  ISIC_2637011  IP_7279968    male        45.0   \n1      1  ISIC_0015719  IP_3075186  female        45.0   \n2      2  ISIC_0052212  IP_2842074  female        50.0   \n3      3  ISIC_0068279  IP_6890425  female        45.0   \n4      4  ISIC_0074268  IP_8723313  female        55.0   \n\n  anatom_site_general_challenge diagnosis benign_malignant  target  tfrecord  \\\n0                     head/neck   unknown           benign       0         0   \n1               upper extremity   unknown           benign       0         0   \n2               lower extremity     nevus           benign       0         6   \n3                     head/neck   unknown           benign       0         0   \n4               upper extremity   unknown           benign       0        11   \n\n   width  height  \n0   6000    4000  \n1   6000    4000  \n2   1872    1053  \n3   1872    1053  \n4   6000    4000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>image_name</th>\n      <th>patient_id</th>\n      <th>sex</th>\n      <th>age_approx</th>\n      <th>anatom_site_general_challenge</th>\n      <th>diagnosis</th>\n      <th>benign_malignant</th>\n      <th>target</th>\n      <th>tfrecord</th>\n      <th>width</th>\n      <th>height</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>ISIC_2637011</td>\n      <td>IP_7279968</td>\n      <td>male</td>\n      <td>45.0</td>\n      <td>head/neck</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6000</td>\n      <td>4000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>ISIC_0015719</td>\n      <td>IP_3075186</td>\n      <td>female</td>\n      <td>45.0</td>\n      <td>upper extremity</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6000</td>\n      <td>4000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>ISIC_0052212</td>\n      <td>IP_2842074</td>\n      <td>female</td>\n      <td>50.0</td>\n      <td>lower extremity</td>\n      <td>nevus</td>\n      <td>benign</td>\n      <td>0</td>\n      <td>6</td>\n      <td>1872</td>\n      <td>1053</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>ISIC_0068279</td>\n      <td>IP_6890425</td>\n      <td>female</td>\n      <td>45.0</td>\n      <td>head/neck</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1872</td>\n      <td>1053</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>ISIC_0074268</td>\n      <td>IP_8723313</td>\n      <td>female</td>\n      <td>55.0</td>\n      <td>upper extremity</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n      <td>11</td>\n      <td>6000</td>\n      <td>4000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean = (0.485, 0.456, 0.406)\nstd = (0.229, 0.224, 0.225)\n# adding a simple augmentation\naug = albumentations.Compose([\n    albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True)\n])\n","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = ClassificationDataset(image_paths=train_images, targets=train_targets, resize=(224,224), augmentations=aug)\ntest_dataset = ClassificationDataset(image_paths=test_images, targets= test_targets, resize=(224,224), augmentations=aug)\n\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for images,targets in test_loader:\n    print(images.shape)","execution_count":9,"outputs":[{"output_type":"stream","text":"torch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([64, 3, 224, 224])\ntorch.Size([30, 3, 224, 224])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","execution_count":10,"outputs":[{"output_type":"stream","text":"cuda:0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# defining model\nmodel = models.resnext50_32x4d(pretrained=True)\nmodel.fc = nn.Sequential(\n    nn.Linear(2048,1000),\n    nn.Dropout(p=0.5),\n    nn.Linear(1000,1)\n)\nmodel.to(device)","execution_count":11,"outputs":[{"output_type":"stream","text":"Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\" to /root/.cache/torch/checkpoints/resnext50_32x4d-7cdf4587.pth\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=100441675.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"540ef018e4ff427d8516d761ec904938"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Sequential(\n    (0): Linear(in_features=2048, out_features=1000, bias=True)\n    (1): Dropout(p=0.5, inplace=False)\n    (2): Linear(in_features=1000, out_features=1, bias=True)\n  )\n)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(model.parameters(), lr=5e-4)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(data_loader, model, optimizer, device):\n    model.train()\n    \n    for images,targets in data_loader:\n        \n        images = images.to(device, dtype=torch.float)\n        targets = targets.to(device, dtype=torch.float) \n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, targets.view(-1,1))\n        loss.backward()\n        optimizer.step()\n    ","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(data_loader, model, device):\n    model.eval()\n    \n    final_targets =  []\n    final_outputs = []\n    \n    with torch.no_grad():\n        for images, targets in data_loader:\n            \n            images = images.to(device, dtype=torch.float)\n            targets = targets.to(device, dtype=torch.float) \n            \n            output = model(images)\n            targets = targets.detach().cpu().numpy().tolist()\n            output = output.detach().cpu().numpy().tolist()\n            \n            # extend the original list\n            final_targets.extend(targets)\n            final_outputs.extend(output)\n            \n    return final_outputs, final_targets","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for epoch in range(5):\n    train(train_loader, model, optimizer, device=device)\n    predictions, valid_targets = evaluate(test_loader, model, device=device)\n    roc_auc = metrics.roc_auc_score(valid_targets, predictions)\n    # f1_score = metrics.f1_score(valid_targets,predictions)\n    print(f\"Epochs={epoch} Valid ROC AUC={roc_auc}\")","execution_count":24,"outputs":[{"output_type":"stream","text":"Epochs=0 Valid ROC AUC=0.8165465096065935\nEpochs=1 Valid ROC AUC=0.8287134901014732\nEpochs=2 Valid ROC AUC=0.8505806153686918\nEpochs=3 Valid ROC AUC=0.8344791712281232\nEpochs=4 Valid ROC AUC=0.8367204221885172\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predictions on test data\ndf = pd.read_csv(root_dir + 'test.csv')\ndf.head()","execution_count":25,"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"     image_name  patient_id     sex  age_approx anatom_site_general_challenge  \\\n0  ISIC_0052060  IP_3579794    male        70.0                           NaN   \n1  ISIC_0052349  IP_7782715    male        40.0               lower extremity   \n2  ISIC_0058510  IP_7960270  female        55.0                         torso   \n3  ISIC_0073313  IP_6375035  female        50.0                         torso   \n4  ISIC_0073502  IP_0589375  female        45.0               lower extremity   \n\n   width  height  \n0   6000    4000  \n1   6000    4000  \n2   6000    4000  \n3   6000    4000  \n4   1920    1080  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>patient_id</th>\n      <th>sex</th>\n      <th>age_approx</th>\n      <th>anatom_site_general_challenge</th>\n      <th>width</th>\n      <th>height</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_0052060</td>\n      <td>IP_3579794</td>\n      <td>male</td>\n      <td>70.0</td>\n      <td>NaN</td>\n      <td>6000</td>\n      <td>4000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0052349</td>\n      <td>IP_7782715</td>\n      <td>male</td>\n      <td>40.0</td>\n      <td>lower extremity</td>\n      <td>6000</td>\n      <td>4000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0058510</td>\n      <td>IP_7960270</td>\n      <td>female</td>\n      <td>55.0</td>\n      <td>torso</td>\n      <td>6000</td>\n      <td>4000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0073313</td>\n      <td>IP_6375035</td>\n      <td>female</td>\n      <td>50.0</td>\n      <td>torso</td>\n      <td>6000</td>\n      <td>4000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0073502</td>\n      <td>IP_0589375</td>\n      <td>female</td>\n      <td>45.0</td>\n      <td>lower extremity</td>\n      <td>1920</td>\n      <td>1080</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class submissionDataset(Dataset):\n    def __init__(self ,image_paths, resize=None, augmentations=None):\n        self.image_paths = image_paths\n        self.resize = resize\n        self.augmentations = augmentations\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, item):\n        image = Image.open(self.image_paths[item])\n        image = image.convert(\"RGB\")\n\n        if self.resize is not None:\n            image = image.resize((self.resize[1], self.resize[0]),\n                                 resample=Image.BILINEAR)\n\n        image = np.array(image)\n\n        if self.augmentations is not None:\n            augmented = self.augmentations(image=image)\n            image = augmented['image']\n\n        # torch expects CxHxW instead of HxWxC\n        image = np.transpose(image, (2,0,1)).astype(np.float32)\n\n        image = torch.tensor(image, dtype=torch.float)\n\n        return image","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_image_ids = df.image_name.values.tolist()\nsub_images = [os.path.join(root_dir + 'test/' ,i +'.jpg') for i in sub_image_ids]\n\nsub_dataset = submissionDataset(image_paths=sub_images, resize=(224,224), augmentations=aug)\nsub_loader = DataLoader(sub_dataset, batch_size=16, shuffle=False, num_workers=4)","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for image in sub_loader:\n    print(image.shape)\n    break","execution_count":31,"outputs":[{"output_type":"stream","text":"torch.Size([16, 3, 224, 224])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_preds(model,device=None,tta=3):\n    if device is None:\n        device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n    preds = np.zeros(len(sub_dataset))\n    for tta_id in range(tta):\n        test_preds = []\n        with torch.no_grad():\n            for image in sub_loader:\n                image = image.to(device)\n                output = model(image)\n                output = torch.sigmoid(output)\n                test_preds.extend(output.cpu().numpy())\n            preds += np.array(test_preds).reshape(-1)\n        print(f'TTA {tta_id}')\n    preds /= tta\n    return preds\n\n#Changing tta to 25 from 10\npreds = get_preds(model,tta=25)  ","execution_count":32,"outputs":[{"output_type":"stream","text":"TTA 0\nTTA 1\nTTA 2\nTTA 3\nTTA 4\nTTA 5\nTTA 6\nTTA 7\nTTA 8\nTTA 9\nTTA 10\nTTA 11\nTTA 12\nTTA 13\nTTA 14\nTTA 15\nTTA 16\nTTA 17\nTTA 18\nTTA 19\nTTA 20\nTTA 21\nTTA 22\nTTA 23\nTTA 24\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"subm = pd.read_csv(root_dir + 'sample_submission.csv')\nsubm.target = preds\nsubm.to_csv('submission.csv',index=False)","execution_count":34,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'path' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-956a042f4868>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msubm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'sample_submission.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msubm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msubm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'submission.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'path' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}
